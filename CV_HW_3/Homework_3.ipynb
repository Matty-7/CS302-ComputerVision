{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### YOUR FULL NAME HERE\n",
    "Netid: Your netid here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "plt.rcParams['axes.labelsize'] = 18\n",
    "plt.rcParams['xtick.labelsize'] = 14\n",
    "plt.rcParams['ytick.labelsize'] = 14\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) POV-Ray and homography\n",
    "**(4 points)**\n",
    "\n",
    "The overall idea of this exercise:  First create two different views of a simple scene containing two cubes using POV-ray:  1) from diagonally above, 2) from the side. Then use a homography to convert 1) into a new picture 3), where 3) has the same viewpoint as 2).  In order to get the 4 pairs of coordinates for determining the homography, you should use the corners of the sidewall of one cube, these are visible in both views, 1) and 2).\n",
    "\n",
    "\n",
    "**a)** Use POV-Ray to create two images: Both contain a horizontal plane going through the origin and two cubes with sidelengths 1 each. The first cube has the origin as one of its corners. The second cube has the same orientation as the first cube, their two neighboring facets are separated by 0.5, and they are aligned in a row. Additionally, choose some interesting surface texture for the cubes.  \n",
    "\n",
    "In image 1) the camera is oriented along one of the diagonales (meaning an axis connecting two opposite corners of the cube) of the first cube. Choose the diagonale such that the second cube is partially hidden behind the first cube. \n",
    "\n",
    "In image 2) the camera view is perpendicular on one of the side facets of the cube such that the second cube is visible next to it.\n",
    "\n",
    "Load and show the two images in your notebook. For submission of your homework you need to upload also the two pov files. (*2 points*) \n",
    "\n",
    "\n",
    "**b)**  We want to compute a homography that creates another side view from image 1). In order to do so, you need to first determine the coordinates of the side face (which in the second image is facing the camera) in both image 1) and 2). These four pairs of coordinates allow you to compute the homography and then warp the perspective of image 1). (*2 points*)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ANSWER**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Green screen segmentation using HSV\n",
    "**(2 points)**\n",
    "\n",
    "Movie productions often happen in front of a green screen. In postproduction the pixels representing the actor are separated by color segmentation (being not green) and copied in front of a different background.\n",
    "\n",
    "Load a photography of yourself in front of a green screen into this notebook, cut away all potentially distracting areas beyond the boundaries of the green screen and display the result. \n",
    "\n",
    "Convert the image to HSV plot some percentage of the points in an HSV cube (with the axes H, S, and V) and determine the thresholds to segment the green background. (You can also use the HSV cylinder from the first homework, but determining the thresholds will be easier in the cube).  *(1 point)*\n",
    "\n",
    "Segment the image, then display both the binary mask representing you and the masked original image (i.e. only you standing in front of a black background). Observe that you only need the hue channel for the segmentation.  *(1 point)*\n",
    "\n",
    "(A small reminder: if you want to combine Boolean values, & corresponds to and and | corresponds to or.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ANSWER**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Rice grains with optimal binarization parameters\n",
    "\n",
    "**(3 points)**\n",
    "\n",
    "Load and display the rice.png image.\n",
    "\n",
    "As you can see the illumination is inhomogeneous which poses a problem for the binarization with a single threshold. As mentioned in the class on segmentation, you can fix this by using a local threshold: for every pixel the average over a square with side length s (in pixels) is computed an then the pixel is binarized with the sum of a) this (local) average and b) a (global) threshold t.\n",
    "\n",
    "Now we need to determine the optimal parameters for s and t. In a first step we would eyeball a range of reasonable values: compute locally binarized images using all for possible combinations of 201 and 501 for s and -40 and -5 for t. Display that four images. *(0.5 points)*\n",
    "\n",
    "As you can see, the influence of s is not strong. And while we have many (wrong) inner contours for s = -40, at s=-5 we start to binarize background noise. So these numbers limit a reasonable range for our search. \n",
    "\n",
    "Now we need a good measure of quality. The number of contours can be a reasonable proxy variable for the quality because both inner boundaries and spurious bachkground pixels will add new wrongful boundaries. So the parameters which give us the minimum count of contours will be the optimum. We could make this argument even more precise by actually counting the number of rice grains by eye and using this number as our target value.\n",
    "\n",
    "Explore the parameter space by using two nested for-loops: The outer loop goes over filter sizes 201, 351, and 501.\n",
    "The inner loop goes t values from -40 to -5. Within that inner loop first perform a local binarization with the parameters from the two loops. Then find the contours and compute the number of found objects with len(contours). Save this result in an array. *(1.5point)*\n",
    "\n",
    "After the nested loops, plot your result with the offset as x-axis and three different curves for the three filter sizes. By choosing the right coordinate ranges you can zoom into the minimum and see which range of the two parameters actually gives an optimal result. *(0.5 points)*\n",
    "\n",
    "Finally, double check your choice by picking one possible parameter combination and binarizing the image that way. Then find the contours and draw them into the original gray value image. *(0.5 points)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
