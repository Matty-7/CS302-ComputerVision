{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "plt.rcParams['axes.labelsize'] = 20\n",
    "plt.rcParams['xtick.labelsize'] = 16\n",
    "plt.rcParams['ytick.labelsize'] = 16\n",
    "%matplotlib inline \n",
    "\n",
    "import cv2\n",
    "from skimage.io import imread\n",
    "from skimage import color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the two images\n",
    "base = imread('ut_plazza_2.jpg')\n",
    "query = imread('ut_plazza_1.jpg')\n",
    "\n",
    "plt.figure(figsize=(18,8))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.imshow(base)\n",
    "plt.axis('off')\n",
    "plt.title('base image', fontsize=20)\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.imshow(query)\n",
    "plt.axis('off')\n",
    "plt.title('query image', fontsize=20)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keypoints for first image\n",
    "base_gray = np.uint8(color.rgb2gray(base)*255)\n",
    "\n",
    "descriptor = cv2.SIFT_create()\n",
    "# for older versions of opencv, try:\n",
    "# descriptor = cv2.xfeatures2d.SIFT_create()\n",
    "keypoints_base, features_base = descriptor.detectAndCompute(base_gray, None)\n",
    "\n",
    "print('first keypoint: \\n', \n",
    "      'keypoint coordinates:', keypoints_base[0].pt, '\\n',\n",
    "      'keypoint scale:', keypoints_base[0].size, '\\n',\n",
    "      'keypoint angle:', keypoints_base[0].angle\n",
    "     )\n",
    "\n",
    "print('feature vector of first keypoint: \\n',features_base[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,10))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.imshow(cv2.drawKeypoints(base_gray, keypoints_base, None, \n",
    "                             color=(255,0,0)))\n",
    "plt.axis('off')\n",
    "plt.title('display all keypoints found', fontsize=20)\n",
    "\n",
    "plt.subplot(122)\n",
    "keypoints_reduced = keypoints_base[0:len(keypoints_base):10]\n",
    "plt.imshow(cv2.drawKeypoints(base_gray, keypoints_reduced, None, \n",
    "                             color=(255,0,0),\n",
    "                             flags = cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS))\n",
    "plt.axis('off')\n",
    "plt.title('indicating scale and angle', fontsize=20)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keypoints for second image\n",
    "query_gray = np.uint8(color.rgb2gray(query)*255)\n",
    "keypoints_query, features_query = descriptor.detectAndCompute(query_gray, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matching points based on their distance\n",
    "bf = cv2.BFMatcher(cv2.NORM_L2, crossCheck=True)\n",
    "\n",
    "matches = bf.match(features_base,features_query)\n",
    "print(\"number of matches (Brute force):\", len(matches))\n",
    "\n",
    "# Sort the features in order of distance.\n",
    "# The points with small distance (more similarity) are ordered first in the vector\n",
    "sorted_matches = sorted(matches, key = lambda x:x.distance)\n",
    "\n",
    "for k in np.arange(0,10):\n",
    "    print('keypoints {} (base) and {} (query) have a feature space distance of {:.2f}'.format(\n",
    "     sorted_matches[k].trainIdx, sorted_matches[k].queryIdx, sorted_matches[k].distance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the first 100 matches\n",
    "matches_img = cv2.drawMatches(base,keypoints_base,query,keypoints_query,sorted_matches[:100],\n",
    "                           None,flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "\n",
    "plt.figure(figsize=(18,10))\n",
    "plt.imshow(matches_img)\n",
    "plt.axis('off')\n",
    "plt.title('the best hundred matches', fontsize=20)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find homography\n",
    "# convert the keypoint coordinates to numpy arrays\n",
    "kp_b = np.float32([kp.pt for kp in keypoints_base])\n",
    "kp_q = np.float32([kp.pt for kp in keypoints_query])\n",
    "\n",
    "# construct the two sets of points\n",
    "pt_b = np.float32([kp_b[m.queryIdx] for m in sorted_matches])\n",
    "pt_q = np.float32([kp_q[m.trainIdx] for m in sorted_matches])\n",
    "\n",
    "# Calculate Homography between source and destination points\n",
    "# 4 is the RANSAC reprojection threshold, i.e. the maximum allowed \n",
    "# distance to treat a point pair as an inlier.\n",
    "h, status = cv2.findHomography(pt_q, pt_b,  cv2.RANSAC, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create panorama by warping query image\n",
    "width = base.shape[1] + query.shape[1]\n",
    "height = base.shape[0] + query.shape[0]\n",
    "\n",
    "result = cv2.warpPerspective(query, h, (width, height))\n",
    "result[0:base.shape[0], 0:base.shape[1]] = base\n",
    "\n",
    "plt.figure(figsize=(20,10)) \n",
    "\n",
    "# uncomment next line to cut to shape\n",
    "#result= result[0:680,0:1580]\n",
    "\n",
    "plt.imshow(result)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In class exercise:\n",
    "copying only the necessary lines from above, panorama stitch your own image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = imread('DKU_left.jpg')\n",
    "\n",
    "print(base.shape)\n",
    "divider = 3\n",
    "base = cv2.resize(base,(base.shape[1]//divider, base.shape[0]//divider))   # // is division and rounding down\n",
    "print(base.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = imread('DKU_right.jpg')\n",
    "query = cv2.resize(query,(query.shape[1]//divider, query.shape[0]//divider))\n",
    "print(query.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
