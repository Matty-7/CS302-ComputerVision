{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, transforms\n",
    "\n",
    "import json\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "devic = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Torch Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KeypointsDataset(Dataset):\n",
    "    def __init__(self, img_dir, data_file):\n",
    "        self.img_dir = img_dir\n",
    "        with open(data_file, \"r\") as f:\n",
    "            self.data = json.load(f)\n",
    "        \n",
    "        self.transforms = transforms.Compose([\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "        img = cv2.imread(f\"{self.img_dir}/{item['id']}.png\")\n",
    "        h,w = img.shape[:2]\n",
    "\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = self.transforms(img)\n",
    "        kps = np.array(item['kps']).flatten()\n",
    "        kps = kps.astype(np.float32)\n",
    "\n",
    "        kps[::2] *= 224.0 / w # Adjust x coordinates\n",
    "        kps[1::2] *= 224.0 / h # Adjust y coordinates\n",
    "\n",
    "        return img, kps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = KeypointsDataset(\"/Users/huanjingheng/CS302-ComputerVision/Tennis/data/images\", \"/Users/huanjingheng/CS302-ComputerVision/Tennis/data/data_train.json\")\n",
    "val_dataset = KeypointsDataset(\"/Users/huanjingheng/CS302-ComputerVision/Tennis/data/images\", \"/Users/huanjingheng/CS302-ComputerVision/Tennis/data/data_val.json\")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /Users/huanjingheng/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
      "100%|██████████| 97.8M/97.8M [00:11<00:00, 8.79MB/s]\n"
     ]
    }
   ],
   "source": [
    "model = models.resnet50(pretrained=True)\n",
    "model.fc = torch.nn.Linear(model.fc.in_features, 14*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(devic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, iter 0, loss 14401.0888671875\n",
      "Epoch 0, iter 10, loss 14187.2607421875\n",
      "Epoch 0, iter 20, loss 14585.845703125\n",
      "Epoch 0, iter 30, loss 14048.771484375\n",
      "Epoch 0, iter 40, loss 13591.0615234375\n",
      "Epoch 0, iter 50, loss 12636.3564453125\n",
      "Epoch 0, iter 60, loss 12650.1669921875\n",
      "Epoch 0, iter 70, loss 12848.7373046875\n",
      "Epoch 0, iter 80, loss 11770.9853515625\n",
      "Epoch 0, iter 90, loss 11932.658203125\n",
      "Epoch 0, iter 100, loss 11506.1943359375\n",
      "Epoch 0, iter 110, loss 10727.5\n",
      "Epoch 0, iter 120, loss 10320.935546875\n",
      "Epoch 0, iter 130, loss 9962.798828125\n",
      "Epoch 0, iter 140, loss 9530.7548828125\n",
      "Epoch 0, iter 150, loss 9589.591796875\n",
      "Epoch 0, iter 160, loss 9145.9931640625\n",
      "Epoch 0, iter 170, loss 8534.787109375\n",
      "Epoch 0, iter 180, loss 8362.966796875\n",
      "Epoch 0, iter 190, loss 8057.16943359375\n",
      "Epoch 0, iter 200, loss 8347.7021484375\n",
      "Epoch 0, iter 210, loss 7823.50244140625\n",
      "Epoch 0, iter 220, loss 6975.08154296875\n",
      "Epoch 0, iter 230, loss 6699.19189453125\n",
      "Epoch 0, iter 240, loss 6424.6748046875\n",
      "Epoch 0, iter 250, loss 6308.33740234375\n",
      "Epoch 0, iter 260, loss 6223.22314453125\n",
      "Epoch 0, iter 270, loss 6305.84765625\n",
      "Epoch 0, iter 280, loss 6147.74609375\n",
      "Epoch 0, iter 290, loss 5422.71142578125\n",
      "Epoch 0, iter 300, loss 5031.87744140625\n",
      "Epoch 0, iter 310, loss 5015.4931640625\n",
      "Epoch 0, iter 320, loss 6125.40966796875\n",
      "Epoch 0, iter 330, loss 4471.17578125\n",
      "Epoch 0, iter 340, loss 5029.69482421875\n",
      "Epoch 0, iter 350, loss 3981.552978515625\n",
      "Epoch 0, iter 360, loss 3613.47265625\n",
      "Epoch 0, iter 370, loss 3830.50048828125\n",
      "Epoch 0, iter 380, loss 4109.52099609375\n",
      "Epoch 0, iter 390, loss 3866.231201171875\n",
      "Epoch 0, iter 400, loss 3993.177734375\n",
      "Epoch 0, iter 410, loss 3275.994384765625\n",
      "Epoch 0, iter 420, loss 2998.177978515625\n",
      "Epoch 0, iter 430, loss 2552.65087890625\n",
      "Epoch 0, iter 440, loss 2959.75048828125\n",
      "Epoch 0, iter 450, loss 2596.747802734375\n",
      "Epoch 0, iter 460, loss 2334.775634765625\n",
      "Epoch 0, iter 470, loss 2134.7451171875\n",
      "Epoch 0, iter 480, loss 2222.995361328125\n",
      "Epoch 0, iter 490, loss 2045.0699462890625\n",
      "Epoch 0, iter 500, loss 1999.823974609375\n",
      "Epoch 0, iter 510, loss 1890.156494140625\n",
      "Epoch 0, iter 520, loss 1677.511474609375\n",
      "Epoch 0, iter 530, loss 1641.5623779296875\n",
      "Epoch 0, iter 540, loss 1205.255859375\n",
      "Epoch 0, iter 550, loss 1810.629150390625\n",
      "Epoch 0, iter 560, loss 1458.8179931640625\n",
      "Epoch 0, iter 570, loss 1327.6785888671875\n",
      "Epoch 0, iter 580, loss 1268.6842041015625\n",
      "Epoch 0, iter 590, loss 1083.0543212890625\n",
      "Epoch 0, iter 600, loss 1107.143310546875\n",
      "Epoch 0, iter 610, loss 845.0987548828125\n",
      "Epoch 0, iter 620, loss 992.9642944335938\n",
      "Epoch 0, iter 630, loss 1017.0245361328125\n",
      "Epoch 0, iter 640, loss 791.1829833984375\n",
      "Epoch 0, iter 650, loss 667.3226318359375\n",
      "Epoch 0, iter 660, loss 603.1641845703125\n",
      "Epoch 0, iter 670, loss 663.4638061523438\n",
      "Epoch 0, iter 680, loss 679.6376953125\n",
      "Epoch 0, iter 690, loss 631.1741333007812\n",
      "Epoch 0, iter 700, loss 736.1136474609375\n",
      "Epoch 0, iter 710, loss 438.9381408691406\n",
      "Epoch 0, iter 720, loss 707.3944091796875\n",
      "Epoch 0, iter 730, loss 442.99859619140625\n",
      "Epoch 0, iter 740, loss 508.9709777832031\n",
      "Epoch 0, iter 750, loss 326.46270751953125\n",
      "Epoch 0, iter 760, loss 371.07098388671875\n",
      "Epoch 0, iter 770, loss 372.7626953125\n",
      "Epoch 0, iter 780, loss 379.8754577636719\n",
      "Epoch 0, iter 790, loss 250.0765838623047\n",
      "Epoch 0, iter 800, loss 261.3346862792969\n",
      "Epoch 0, iter 810, loss 243.76588439941406\n",
      "Epoch 0, iter 820, loss 219.798583984375\n",
      "Epoch 1, iter 0, loss 185.87171936035156\n",
      "Epoch 1, iter 10, loss 255.60830688476562\n",
      "Epoch 1, iter 20, loss 191.10633850097656\n",
      "Epoch 1, iter 30, loss 305.3065490722656\n",
      "Epoch 1, iter 40, loss 185.07899475097656\n",
      "Epoch 1, iter 50, loss 309.99078369140625\n",
      "Epoch 1, iter 60, loss 212.4030303955078\n",
      "Epoch 1, iter 70, loss 254.3087158203125\n",
      "Epoch 1, iter 80, loss 145.500244140625\n",
      "Epoch 1, iter 90, loss 147.6607208251953\n",
      "Epoch 1, iter 100, loss 103.35072326660156\n",
      "Epoch 1, iter 110, loss 129.1195068359375\n",
      "Epoch 1, iter 120, loss 71.61505889892578\n",
      "Epoch 1, iter 130, loss 115.88697814941406\n",
      "Epoch 1, iter 140, loss 98.02240753173828\n",
      "Epoch 1, iter 150, loss 91.1778335571289\n",
      "Epoch 1, iter 160, loss 69.26762390136719\n",
      "Epoch 1, iter 170, loss 62.39400863647461\n",
      "Epoch 1, iter 180, loss 123.90404510498047\n",
      "Epoch 1, iter 190, loss 74.3276596069336\n",
      "Epoch 1, iter 200, loss 103.08124542236328\n",
      "Epoch 1, iter 210, loss 58.336517333984375\n",
      "Epoch 1, iter 220, loss 46.6947021484375\n",
      "Epoch 1, iter 230, loss 98.02167510986328\n",
      "Epoch 1, iter 240, loss 80.95259857177734\n",
      "Epoch 1, iter 250, loss 59.988059997558594\n",
      "Epoch 1, iter 260, loss 64.50284576416016\n",
      "Epoch 1, iter 270, loss 41.563663482666016\n",
      "Epoch 1, iter 280, loss 84.52867889404297\n",
      "Epoch 1, iter 290, loss 44.28084182739258\n",
      "Epoch 1, iter 300, loss 54.45174789428711\n",
      "Epoch 1, iter 310, loss 73.85533905029297\n",
      "Epoch 1, iter 320, loss 145.13162231445312\n",
      "Epoch 1, iter 330, loss 26.146039962768555\n",
      "Epoch 1, iter 340, loss 27.210481643676758\n",
      "Epoch 1, iter 350, loss 41.002193450927734\n",
      "Epoch 1, iter 360, loss 20.985048294067383\n",
      "Epoch 1, iter 370, loss 31.179059982299805\n",
      "Epoch 1, iter 380, loss 55.821327209472656\n",
      "Epoch 1, iter 390, loss 51.06250762939453\n",
      "Epoch 1, iter 400, loss 36.88376235961914\n",
      "Epoch 1, iter 410, loss 53.628360748291016\n",
      "Epoch 1, iter 420, loss 62.648193359375\n",
      "Epoch 1, iter 430, loss 56.94690704345703\n",
      "Epoch 1, iter 440, loss 33.90555191040039\n",
      "Epoch 1, iter 450, loss 85.94169616699219\n",
      "Epoch 1, iter 460, loss 32.35002899169922\n",
      "Epoch 1, iter 470, loss 114.53516387939453\n",
      "Epoch 1, iter 480, loss 24.633663177490234\n",
      "Epoch 1, iter 490, loss 102.18306732177734\n",
      "Epoch 1, iter 500, loss 36.632843017578125\n",
      "Epoch 1, iter 510, loss 22.750925064086914\n",
      "Epoch 1, iter 520, loss 24.49333381652832\n",
      "Epoch 1, iter 530, loss 139.7878875732422\n",
      "Epoch 1, iter 540, loss 63.5519905090332\n",
      "Epoch 1, iter 550, loss 27.235445022583008\n",
      "Epoch 1, iter 560, loss 45.856685638427734\n",
      "Epoch 1, iter 570, loss 43.726287841796875\n",
      "Epoch 1, iter 580, loss 53.79257583618164\n",
      "Epoch 1, iter 590, loss 90.6127700805664\n",
      "Epoch 1, iter 600, loss 47.21114730834961\n",
      "Epoch 1, iter 610, loss 20.869272232055664\n",
      "Epoch 1, iter 620, loss 31.660627365112305\n",
      "Epoch 1, iter 630, loss 43.35599899291992\n",
      "Epoch 1, iter 640, loss 19.5882568359375\n",
      "Epoch 1, iter 650, loss 58.497310638427734\n",
      "Epoch 1, iter 660, loss 64.49285125732422\n",
      "Epoch 1, iter 670, loss 35.88834762573242\n",
      "Epoch 1, iter 680, loss 34.72269058227539\n",
      "Epoch 1, iter 690, loss 35.39237976074219\n",
      "Epoch 1, iter 700, loss 151.09402465820312\n",
      "Epoch 1, iter 710, loss 34.19325637817383\n",
      "Epoch 1, iter 720, loss 25.910337448120117\n",
      "Epoch 1, iter 730, loss 85.62770080566406\n",
      "Epoch 1, iter 740, loss 87.89513397216797\n",
      "Epoch 1, iter 750, loss 40.75670623779297\n",
      "Epoch 1, iter 760, loss 21.158588409423828\n",
      "Epoch 1, iter 770, loss 33.79990768432617\n",
      "Epoch 1, iter 780, loss 102.1204605102539\n",
      "Epoch 1, iter 790, loss 62.69024658203125\n",
      "Epoch 1, iter 800, loss 88.1072006225586\n",
      "Epoch 1, iter 810, loss 14.703722953796387\n",
      "Epoch 1, iter 820, loss 35.47481918334961\n",
      "Epoch 2, iter 0, loss 44.81229019165039\n",
      "Epoch 2, iter 10, loss 36.993534088134766\n",
      "Epoch 2, iter 20, loss 68.27083587646484\n",
      "Epoch 2, iter 30, loss 13.211899757385254\n",
      "Epoch 2, iter 40, loss 23.656095504760742\n",
      "Epoch 2, iter 50, loss 32.30891036987305\n",
      "Epoch 2, iter 60, loss 32.32489013671875\n",
      "Epoch 2, iter 70, loss 15.99793529510498\n",
      "Epoch 2, iter 80, loss 24.873666763305664\n",
      "Epoch 2, iter 90, loss 30.25062370300293\n",
      "Epoch 2, iter 100, loss 39.4744987487793\n",
      "Epoch 2, iter 110, loss 45.26392364501953\n",
      "Epoch 2, iter 120, loss 31.7340030670166\n",
      "Epoch 2, iter 130, loss 17.309083938598633\n",
      "Epoch 2, iter 140, loss 64.47736358642578\n",
      "Epoch 2, iter 150, loss 97.8064956665039\n",
      "Epoch 2, iter 160, loss 23.66133689880371\n",
      "Epoch 2, iter 170, loss 28.286052703857422\n",
      "Epoch 2, iter 180, loss 52.233978271484375\n",
      "Epoch 2, iter 190, loss 33.079410552978516\n",
      "Epoch 2, iter 200, loss 46.70096206665039\n",
      "Epoch 2, iter 210, loss 51.29803466796875\n",
      "Epoch 2, iter 220, loss 30.965511322021484\n",
      "Epoch 2, iter 230, loss 25.091054916381836\n",
      "Epoch 2, iter 240, loss 28.006425857543945\n",
      "Epoch 2, iter 250, loss 26.68452262878418\n",
      "Epoch 2, iter 260, loss 209.52365112304688\n",
      "Epoch 2, iter 270, loss 37.814720153808594\n",
      "Epoch 2, iter 280, loss 28.29776954650879\n",
      "Epoch 2, iter 290, loss 22.636999130249023\n",
      "Epoch 2, iter 300, loss 86.86335754394531\n",
      "Epoch 2, iter 310, loss 45.436439514160156\n",
      "Epoch 2, iter 320, loss 21.101106643676758\n",
      "Epoch 2, iter 330, loss 18.77528953552246\n",
      "Epoch 2, iter 340, loss 14.706162452697754\n",
      "Epoch 2, iter 350, loss 21.0135555267334\n",
      "Epoch 2, iter 360, loss 22.866470336914062\n",
      "Epoch 2, iter 370, loss 22.83828353881836\n",
      "Epoch 2, iter 380, loss 24.928396224975586\n",
      "Epoch 2, iter 390, loss 16.464292526245117\n",
      "Epoch 2, iter 400, loss 64.18780517578125\n",
      "Epoch 2, iter 410, loss 42.04805374145508\n",
      "Epoch 2, iter 420, loss 66.92076110839844\n",
      "Epoch 2, iter 430, loss 37.55997848510742\n",
      "Epoch 2, iter 440, loss 29.342283248901367\n",
      "Epoch 2, iter 450, loss 54.45490646362305\n",
      "Epoch 2, iter 460, loss 55.418907165527344\n",
      "Epoch 2, iter 470, loss 22.837854385375977\n",
      "Epoch 2, iter 480, loss 17.824987411499023\n",
      "Epoch 2, iter 490, loss 74.6230697631836\n",
      "Epoch 2, iter 500, loss 31.12681770324707\n",
      "Epoch 2, iter 510, loss 63.87675094604492\n",
      "Epoch 2, iter 520, loss 119.59893035888672\n",
      "Epoch 2, iter 530, loss 34.68626022338867\n",
      "Epoch 2, iter 540, loss 31.38813591003418\n",
      "Epoch 2, iter 550, loss 71.90093994140625\n",
      "Epoch 2, iter 560, loss 39.9276237487793\n",
      "Epoch 2, iter 570, loss 63.344276428222656\n",
      "Epoch 2, iter 580, loss 28.432632446289062\n",
      "Epoch 2, iter 590, loss 20.94363784790039\n",
      "Epoch 2, iter 600, loss 24.687808990478516\n",
      "Epoch 2, iter 610, loss 27.808137893676758\n",
      "Epoch 2, iter 620, loss 18.068655014038086\n",
      "Epoch 2, iter 630, loss 12.523109436035156\n",
      "Epoch 2, iter 640, loss 17.647226333618164\n",
      "Epoch 2, iter 650, loss 88.21112823486328\n",
      "Epoch 2, iter 660, loss 30.107769012451172\n",
      "Epoch 2, iter 670, loss 22.962810516357422\n",
      "Epoch 2, iter 680, loss 36.85009002685547\n",
      "Epoch 2, iter 690, loss 71.89362335205078\n",
      "Epoch 2, iter 700, loss 40.20178985595703\n",
      "Epoch 2, iter 710, loss 23.92605209350586\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "for epoch in range(epochs):\n",
    "    for i, (imgs, kps) in enumerate(train_loader):\n",
    "        imgs = imgs.to(devic)\n",
    "        kps = kps.to(devic)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(imgs)\n",
    "        loss = criterion(outputs, kps)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if i % 10 == 0:\n",
    "            print(f\"Epoch {epoch}, iter {i}, loss {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"keypoints_model.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
