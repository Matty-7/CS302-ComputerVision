{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "plt.rcParams['axes.labelsize'] = 18\n",
    "plt.rcParams['xtick.labelsize'] = 14\n",
    "plt.rcParams['ytick.labelsize'] = 14\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## prepare data #########################\n",
    "# load MNIST and split between training  and testing data sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "print('training data:', x_train.shape[0], 'images with', x_train.shape[1], 'times', x_train.shape[2], 'pixels')\n",
    "print('test data:', x_test.shape[0], 'images with', x_test.shape[1], 'times', x_test.shape[2], 'pixels \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert images into 1D vectors with 28^2 = 784 components \n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "\n",
    "# normalize features to float in range 0..1\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "print('training data:', x_train.shape[0], 'images with', x_train.shape[1], 'features')\n",
    "print('test data:', x_test.shape[0], 'images with', x_test.shape[1], 'features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert target values to one hot vectors \n",
    "print('original y data example:', y_train[0])\n",
    "y_train = keras.utils.to_categorical(y_train, 10)\n",
    "y_test = keras.utils.to_categorical(y_test, 10)\n",
    "print('after converting to a one hot vector:', y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preview the images\n",
    "plt.figure(figsize=(12,10))\n",
    "x, y =5, 4\n",
    "for i in range(20):  \n",
    "    plt.subplot(y, x, i+1)\n",
    "    plt.imshow(x_train[i].reshape((28,28)),cmap='gray')\n",
    "    plt.title('target: {}'.format(np.argmax(y_train[i])))\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# let's start with a simple model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# design a simple neural network\n",
    "model = Sequential()\n",
    "model.add(Dense(15, activation='relu', input_shape=(784,)))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer= Adam(),                             \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First layer has 15 Neurons which are each connected to 784 pixels -> this corresponds to 11760 weight. Additionally we need 15 biases for the 15 neurons.\n",
    "\n",
    "#### Second layer has 10 (output) neurons, each connected to 15 neurons from the first layer -> 150 weights plus 10 biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "batch_size = 128\n",
    "epochs = 20\n",
    "\n",
    "#history simple will save our training results\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,              \n",
    "                    validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model performance\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Test loss: {:.4f}\".format(score[0]))\n",
    "print(\"Test accuracy: {:.4f}\".format(score[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the learning process\n",
    "accuracy = history.history['accuracy']\n",
    "val_accuracy = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(len(accuracy))\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(epochs, accuracy, 'bo', label='Training')\n",
    "plt.plot(epochs, val_accuracy, 'r', label='Test')\n",
    "plt.xlabel('Epoch', size=18)\n",
    "plt.ylabel('Accuracy', size=18)\n",
    "plt.xticks(np.arange(0, 21, step=5))\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(epochs, loss, 'bo', label='Training')\n",
    "plt.plot(epochs, val_loss, 'r', label='Test')\n",
    "plt.xlabel('Epoch', size=18)\n",
    "plt.ylabel('Loss', size=18)\n",
    "plt.xticks(np.arange(0, 21, step=5))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's have a look at the results\n",
    "# make predictions for all test data\n",
    "y_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick an example from the test data\n",
    "n = 0\n",
    "\n",
    "np.set_printoptions(precision=1)\n",
    "print('predicted probabilities: ', y_pred[n])\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.imshow(x_test[n].reshape((28,28)),cmap='gray')\n",
    "plt.title('target: {} predicted: {}'.format(np.argmax(y_test[n]), np.argmax(y_test[n]), size=16))\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert one hot back to vector\n",
    "print(y_test.shape)\n",
    "Y_test = np.argmax(y_test, axis = 1)\n",
    "Y_pred = np.argmax(y_pred, axis = 1)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the result\n",
    "plt.figure(figsize=(12,12))\n",
    "x, y =5, 4\n",
    "for i in range(20):  \n",
    "    plt.subplot(y, x, i+1)\n",
    "    plt.imshow(x_test[i].reshape((28,28)),cmap='gray')\n",
    "    plt.title('target: {}\\npredicted: {}'.format(Y_test[i], Y_pred[i]))\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "cm1 = metrics.confusion_matrix(Y_test, Y_pred)\n",
    "\n",
    "plt.figure(figsize=(9,9))\n",
    "sns.heatmap(cm1, annot=True, fmt=\".0f\", linewidths=.5, square=True, cmap='Blues_r')\n",
    "plt.ylabel('true number', size=17)\n",
    "plt.xlabel('predicted number', size=17)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's have a look at the errors\n",
    "errors = (Y_pred - Y_test != 0)\n",
    "error_pos = np.array(np.where(errors))\n",
    "print('total number of errors:', len(error_pos[0,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the errors\n",
    "plt.figure(figsize=(12,12))\n",
    "x, y =5, 4\n",
    "for i in range(20):  \n",
    "    plt.subplot(y, x, i+1)\n",
    "    idx = error_pos[0,i] \n",
    "    plt.imshow(x_test[idx].reshape((28,28)),cmap='gray')\n",
    "    plt.title('target: {}\\npredicted: {}'.format(Y_test[idx], Y_pred[idx]))\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### in class exercise: \n",
    "create a second model named model_2 with 32 neurons in a first hidden layer, 16 neurons in a second hidden layer, and again 10 output neurons. Train the new model for 20 epochs (don't forget to compile it) and plot the learning curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the learning process\n",
    "accuracy = history.history['accuracy']\n",
    "val_accuracy = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(len(accuracy))\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(epochs, accuracy, 'bo', label='Training')\n",
    "plt.plot(epochs, val_accuracy, 'r', label='Test')\n",
    "plt.xlabel('Epoch', size=18)\n",
    "plt.ylabel('Accuracy', size=18)\n",
    "plt.xticks(np.arange(0, 21, step=5))\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(epochs, loss, 'bo', label='Training')\n",
    "plt.plot(epochs, val_loss, 'r', label='Test')\n",
    "plt.xlabel('Epoch', size=18)\n",
    "plt.ylabel('Loss', size=18)\n",
    "plt.xticks(np.arange(0, 21, step=5))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model performance\n",
    "score = model_2.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Test accuracy: {:.4f}\".format(score[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
