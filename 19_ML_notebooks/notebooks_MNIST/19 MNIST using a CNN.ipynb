{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten   # required for CNN\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "plt.rcParams['axes.labelsize'] = 18\n",
    "plt.rcParams['xtick.labelsize'] = 14\n",
    "plt.rcParams['ytick.labelsize'] = 14\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# split between training  and testing data sets\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "######### new #####################\n",
    "# add an extra dimension to adapt BW image to CNN\n",
    "print(X_train.shape)\n",
    "X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
    "print(X_train.shape)\n",
    "\n",
    "X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n",
    "\n",
    "\n",
    "# normalize data to float in range 0..1\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "######### new #####################\n",
    "# no need to convert target values to one hot vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# built a Convolutional Neural Network\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=(28,28,1)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', # no need to use a one hot vector\n",
    "              optimizer=keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolution layers: <br>\n",
    "number of parameters = (filter_height * filter_width * input_image_channels + 1) * number_of_filters <br>\n",
    "(+ 1 is for bias)\n",
    "1. convolution layer = (3 * 3 * 1 + 1 ) * 32  = 320 <br>\n",
    "2. convolution layer = (3 * 3 * 32 + 1 ) * 64  = 18496 <br>\n",
    "\n",
    "Dense layers: <br>\n",
    "number of parameters = (number of neurons previous layer + 1) * number of neurons this layer \n",
    "1. dense layer = (9216 +1) * 128 = 1 179 776\n",
    "2. dense layer = (128 +1) * 10 = 1290"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load saved weights for the model\n",
    "# model.load_weights('CNN_20_epochs_128_batch_Adam.h5')\n",
    "\n",
    "# and/or train the model\n",
    "batch_size = 128\n",
    "epochs = 20\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, y_test))\n",
    "\n",
    "\n",
    "\n",
    "# save the weights\n",
    "model.save_weights('CNN_20_epochs_128_batch_Adam.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### notebook stores last set of weights, running training again starts from the \"pre-trained\" model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss: {:.4}'.format(score[0]))\n",
    "print('Test accuracy: {:.4}'.format(score[1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.9190 accuracy with logistic regeression and l2 regularization\n",
    "\n",
    "0.9662 accuracy with random forest of 40 trees\n",
    "\n",
    "0.9485 accuracy with simple NN model  (Trainable params: 11,935) \n",
    "\n",
    "0.9815 accuracy with complex NN model  (Trainable params: 669,706) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the learning process\n",
    "accuracy = history.history['accuracy']\n",
    "val_accuracy = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1,len(accuracy)+1)\n",
    "\n",
    "plt.figure(figsize=(14,9))\n",
    "plt.plot(epochs, accuracy, 'bo', label='Training')\n",
    "plt.plot(epochs, val_accuracy, 'r', label='Test')\n",
    "plt.xlabel('Epoch', size=14)\n",
    "plt.ylabel('Accuracy', size=14)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(14,9))\n",
    "plt.plot(epochs, loss, 'bo', label='Training')\n",
    "plt.plot(epochs, val_loss, 'r', label='Test')\n",
    "plt.xlabel('Epoch', size=14)\n",
    "plt.ylabel('Loss', size=14)\n",
    "plt.legend()\n",
    "#plt.savefig('loss.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "# convert one hot to vector\n",
    "y_pred = np.argmax(y_pred, axis = 1)\n",
    "\n",
    "cm1 = metrics.confusion_matrix(y_test, y_pred)\n",
    "\n",
    "plt.figure(figsize=(7,7))\n",
    "sns.heatmap(cm1, annot=True, fmt=\".0f\", linewidths=.5, square=True, cmap='Blues_r')\n",
    "plt.ylabel('true number', size=17)\n",
    "plt.xlabel('predicted number', size=17)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's have a look at the errors\n",
    "errors = (y_pred - y_test != 0)\n",
    "error_pos = np.array(np.where(errors))\n",
    "print('total number of errors:', len(error_pos[0,:]))\n",
    "\n",
    "# show the errors\n",
    "plt.figure(figsize=(12,12))\n",
    "x, y =5, 4\n",
    "for i in range(20):  \n",
    "    plt.subplot(y, x, i+1)\n",
    "    idx = error_pos[0,i] \n",
    "    plt.imshow(X_test[idx].reshape((28,28)),cmap='gray')\n",
    "    plt.title('target: {}\\npredicted: {}'.format(y_test[idx], y_pred[idx]))\n",
    "    plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
