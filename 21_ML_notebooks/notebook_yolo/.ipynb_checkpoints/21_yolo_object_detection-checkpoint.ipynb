{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOLO object detection using OpenCV\n",
    "\n",
    "Based on code by Chieko Natori: https://github.com/ChiekoN/yolov3_opencv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "plt.rcParams['axes.labelsize'] = 18\n",
    "plt.rcParams['xtick.labelsize'] = 14\n",
    "plt.rcParams['ytick.labelsize'] = 14\n",
    "%matplotlib inline\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# code requires the following minimum library versions\n",
    "# OpenCV 3.4.2\n",
    "import cv2\n",
    "\n",
    "print(\"OpenCV version {}\".format(cv2.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the category names of the coco dataset used for training\n",
    "\n",
    "# set path\n",
    "coco_names_file = \"yolo/coco.names\"\n",
    "\n",
    "# read coco object names\n",
    "LABELS = open(coco_names_file).read().strip().split(\"\\n\")\n",
    "\n",
    "print('The COCO dataset contains images of the following items: \\n', LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure YOLOv3\n",
    "\n",
    "# set paths to config files\n",
    "yolov3_weight_file = \"yolo/yolov3.weights\"\n",
    "yolov3_config_file = \"yolo/yolov3.cfg\"\n",
    "\n",
    "# built YOLO network\n",
    "net = cv2.dnn.readNetFromDarknet(yolov3_config_file, yolov3_weight_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print information about all layers in the YOLO v3 model\n",
    "\n",
    "# get all layer names in the network\n",
    "ln = net.getLayerNames()\n",
    "print(\"YOLO v3 has {} layers:\".format(len(ln)))\n",
    "print(ln)\n",
    "\n",
    "# the output layers are those with unconnected output\n",
    "ln_out = [ln[i - 1] for i in net.getUnconnectedOutLayers()]\n",
    "print(\"\\nNames of YOLO v3 output layers: \\n{}\".format(ln_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read image file\n",
    "from skimage.io import imread\n",
    "\n",
    "#image = imread(\"images/lunch.jpg\")\n",
    "image = imread(\"images/perth.jpg\")\n",
    "#image = imread(\"images/crossing.jpg\")\n",
    "#image = imread(\"images/coffee.jpg\")\n",
    "#image = imread(\"images/wiener_kaffeehaus_2.jpg\")\n",
    "#image = imread(\"images/black_and_white.jpg\")\n",
    "\n",
    "# determine image size -> will be needed to rescale bounding boxes\n",
    "(h, w) = image.shape[:2]\n",
    "\n",
    "# preprocess image data with rescaling and resizing, using RGB which is unusual for opencv\n",
    "blob = cv2.dnn.blobFromImage(image, 1 / 255.0, (416, 416), crop=False)\n",
    "print('Format of blob: {}'.format(blob.shape))\n",
    "\n",
    "# we need to convert the blob in order to be able to show it\n",
    "blob_to_show = blob[0, :, :, :].transpose(1, 2, 0)\n",
    "print('Format of blob_to_show: {}'.format(blob_to_show.shape))\n",
    "\n",
    "# visualize result of preprocessing\n",
    "plt.figure(figsize = (8,8))\n",
    "plt.imshow(blob_to_show)\n",
    "plt.title('image resized', size = 16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### the actual inference #########\n",
    "# set a new input to the network\n",
    "net.setInput(blob)\n",
    "\n",
    "# mesasure the time needed for the object detection \n",
    "start = time.time()\n",
    "layerOutputs = net.forward(ln_out)\n",
    "end = time.time()\n",
    "\n",
    "# Showing spent time for forward pass\n",
    "print('YOLO v3 took {:.4f} seconds'.format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's have a look at the output\n",
    "# Check point\n",
    "print('The output of YOLO v3 is a', type(layerOutputs), 'consisting of', len(layerOutputs) , type(layerOutputs[0])) \n",
    "\n",
    "print('\\nThe size of the numpy arrays is:')\n",
    "print(ln_out[0], ':', layerOutputs[0].shape)\n",
    "print(ln_out[1], ':', layerOutputs[1].shape)\n",
    "print(ln_out[2], ':', layerOutputs[2].shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### why 85 features per bounding box?\n",
    "There are the 80 classes in the COCO training set and the 5 parameters (x, y, width, height, object confidence).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### why the number of bounding boxes?\n",
    "\n",
    "The number of (possible) bounding boxes is the number of grid positions in that layer times the number of (anchor) bounding boxes per grid position (three here): \n",
    "\n",
    " - **yolo_82**:  grid shape = 13 x 13 ---> 13 x 13 x 3 =  **507**, (detects *BIGGER OBJECTS*)\n",
    " - **yolo_94**:  grid shape = 26 x 26 ---> 26 x 26 x 3 = **2028**\n",
    " - **yolo_106**: grid shape = 52 x 52 ---> 52 x 52 x 3 = **8112**, (detects *SMALLER OBJECTS*) \n",
    "\n",
    "*Reference:* https://towardsdatascience.com/yolo-v3-object-detection-53fb7d3bfe6b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at one of the bounding box predictions:\n",
    "# Note: In YOLO v3, each class is seperately predicted using *logistic regression* instead of *softmax*. \n",
    "# This allows the model to predict, for example, the image of a woman as 'person' and as 'woman' at the same time.\n",
    "\n",
    "# we take the first bounding box of the first output layer\n",
    "\n",
    "print('x, y, width, height of the bounding box:\\n',  layerOutputs[0][0 ,:4])\n",
    "print('object confidence:\\n',  layerOutputs[0][0 ,4])\n",
    "print('predictions for the 80 class probabilities:\\n',  layerOutputs[0][0 ,5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this cell :\n",
    "# - merges the three outputs \n",
    "# - removes all empty bounding boxes (i.e. class_probability < threshold ), \n",
    "# - rescales the bounding boxes\n",
    "\n",
    "# Preparing lists for detected bounding boxes, obtained confidences and class's number\n",
    "boxes = []\n",
    "scores = []\n",
    "classes = []\n",
    "\n",
    "# this is our threshold for keeping the bounding box\n",
    "probability_minimum =0.5\n",
    "\n",
    "# iterating through all three outputs\n",
    "for result in layerOutputs:\n",
    "    # Going through all bounding boxes from current output layer\n",
    "    for detection in result:\n",
    "        \n",
    "        # Getting class for current object\n",
    "        scores_current = detection[5:]\n",
    "        class_current = np.argmax(scores_current)\n",
    "\n",
    "        # Getting probability for current object\n",
    "        probability_current = scores_current[class_current]\n",
    "\n",
    "        # Getting object confidence for current object\n",
    "        object_confidence = detection[4]\n",
    "        \n",
    "        # Eliminating weak predictions by minimum probability\n",
    "        if probability_current > probability_minimum:\n",
    "        #if probability_current*object_confidence > probability_minimum:  # this is an alternative way\n",
    "        \n",
    "        \n",
    "            # Scaling bounding box coordinates to the initial image size\n",
    "            # by elementwise multiplying them with the width and height of the image\n",
    "            box_current = np.array(detection[0:4]) * np.array([w, h, w, h])\n",
    "\n",
    "            # YOLO data format keeps center of detected box and its width and height\n",
    "            # here we reconstruct the top left and bottom right corner\n",
    "            x_center, y_center, box_width, box_height = box_current.astype('int')\n",
    "            x_min = int(x_center - (box_width / 2))\n",
    "            y_min = int(y_center - (box_height / 2))\n",
    "            x_max = int(x_center + (box_width / 2))\n",
    "            y_max = int(y_center + (box_height / 2))\n",
    "            \n",
    "\n",
    "            # Adding results into prepared lists\n",
    "            boxes.append([x_min, y_min, x_max, y_max])\n",
    "            scores.append(float(probability_current))\n",
    "            classes.append(class_current)\n",
    "            \n",
    "classes=np.array(classes)   \n",
    "scores=np.array(scores)\n",
    "boxes=np.array(boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what do we find\n",
    "for i in range(len(scores)):\n",
    "    print(LABELS[classes[i]], 'with probability {:.3} at position{}'.format(scores[i],boxes[i,:]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw bounding boxes on a copy of the image\n",
    "image_copy = np.copy(image)\n",
    "\n",
    "# assign random colours to the class labels, these are used to draw the bounding boxes\n",
    "np.random.seed(42)\n",
    "COLORS = np.random.randint(0, 255, size=(len(LABELS), 3), dtype=\"uint8\")\n",
    "border_thickness = 2\n",
    "\n",
    "# parameters text\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "font_scale = 0.7\n",
    "text_thickness = 2\n",
    "text_offset_x = 7\n",
    "text_offset_y = 7\n",
    "\n",
    "for box in range(len(scores)):\n",
    "    # draw the bounding box\n",
    "    color = tuple([int(c) for c in COLORS[classes[box]]])\n",
    "\n",
    "    (pt1_x, pt1_y) = (int(boxes[box, 0]), int(boxes[box, 1]))\n",
    "    (pt2_x, pt2_y) = (int(boxes[box, 2]), int(boxes[box, 3]))\n",
    "    \n",
    "    cv2.rectangle(image_copy, (pt1_x, pt1_y), (pt2_x, pt2_y), color, border_thickness)\n",
    "    \n",
    "    \n",
    "    # print the label\n",
    "    text = \"{}: {:.4f}\".format(LABELS[classes[box]], scores[box])\n",
    "    (t_w, t_h), _ = cv2.getTextSize(text, font, fontScale=font_scale, thickness=text_thickness)\n",
    "    (text_box_x1, text_box_y1) = (pt1_x, pt1_y - (t_h + text_offset_y))\n",
    "    (test_box_x2, text_box_y2) = ((pt1_x + t_w + text_offset_x), pt1_y)\n",
    "    \n",
    "    cv2.rectangle(image_copy, (text_box_x1, text_box_y1), (test_box_x2, text_box_y2), color, cv2.FILLED)   \n",
    "    cv2.putText(image_copy, text, (pt1_x + text_offset_x,pt1_y - 5), font, font_scale, \n",
    "                                (255, 255, 255), text_thickness)\n",
    "\n",
    "                  \n",
    "plt.figure(figsize=(w*0.05, h*0.05))\n",
    "plt.imshow(image_copy)\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non Max Supression\n",
    "\n",
    " 1. Select the box that has the highest score.\n",
    "\n",
    " 2. Compute its overlap with all other boxes (IoU), and remove boxes that overlap it more than iou_threshold.\n",
    " \n",
    " 3. Bo back to setp 1 and iterate until there's no more boxes with a lower score than the current selected box."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou(box1, box2):\n",
    "    # Caculate IoU between box1 and box2\n",
    "    #    box1/box2 : (x1, y1, x2, y2), where x1 and y1 are coordinates of upper left corner, \n",
    "    #                x2 and y2 are of lower right corner\n",
    "    #    return: IoU\n",
    "    \n",
    "    # get the area of intersection \n",
    "    # top left corner\n",
    "    xi1 = max(box1[0], box2[0])\n",
    "    yi1 = max(box1[1], box2[1])\n",
    "    # bottom right corner\n",
    "    xi2 = min(box1[2], box2[2])\n",
    "    yi2 = min(box1[3], box2[3])\n",
    "\n",
    "    # max answers questioon: is there and intersection at all\n",
    "    inter_area = max(xi2 - xi1, 0) * max(yi2 - yi1, 0)\n",
    "    \n",
    "    # get the area of union\n",
    "    box1_area = (box1[2] - box1[0]) * (box1[3] - box1[1])\n",
    "    box2_area = (box2[2] - box2[0]) * (box2[3] - box2[1])\n",
    "    \n",
    "    union_area = box1_area + box2_area - inter_area\n",
    "    \n",
    "    # get iou\n",
    "    iou = inter_area / union_area\n",
    "    \n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolo_non_max_supression(boxes, scores, score_threshold=0.5, iou_threshold=0.5):\n",
    "    #  Apply Non-max supression.\n",
    "    #    boxes : Array of coordinates of boxes (x1, y1, x2, y2)\n",
    "    #    scores : Array of confidence scores with respect to boxes\n",
    "    #    score_threshold : Threshold, higher will be kept\n",
    "    #    iou_threshold : if iou is below threshold, keep both boxes\n",
    "    #    Return : Indices of boxes and scores to be kept\n",
    "    \n",
    "    sorted_idx = np.argsort(scores)[::-1]\n",
    "    \n",
    "    remove = []\n",
    "    for i in np.arange(len(scores)):\n",
    "        if i in remove:   # already processed\n",
    "            continue\n",
    "        if scores[sorted_idx[i]] < score_threshold:   # score below threshold?\n",
    "            remove.append(i)\n",
    "            continue\n",
    "            \n",
    "        for j in np.arange(i+1, len(scores)):     # go through remaining boxes of list\n",
    "            if scores[sorted_idx[j]] < score_threshold:\n",
    "                remove.append(j)\n",
    "                continue\n",
    "                \n",
    "            overlap = iou(boxes[sorted_idx[i]], boxes[sorted_idx[j]])\n",
    "            if overlap > iou_threshold:   # remove second box, which has smaller score due to sorting\n",
    "                remove.append(j)\n",
    "                \n",
    "    sorted_idx = np.delete(sorted_idx, remove)  # clean the list\n",
    "\n",
    "    return sorted(sorted_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Non-max supression\n",
    "print('we start with ', len(scores), 'indices')\n",
    "nms_idx = yolo_non_max_supression(boxes, scores, score_threshold=0.5, iou_threshold = 0.5)\n",
    "print(len(nms_idx), 'indices are kept:', nms_idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw bounding boxes on the image\n",
    "\n",
    "for box in nms_idx:\n",
    "    # draw the bounding box\n",
    "    color = tuple([int(c) for c in COLORS[classes[box]]])\n",
    "\n",
    "    (pt1_x, pt1_y) = (int(boxes[box, 0]), int(boxes[box, 1]))\n",
    "    (pt2_x, pt2_y) = (int(boxes[box, 2]), int(boxes[box, 3]))\n",
    "    \n",
    "    cv2.rectangle(image, (pt1_x, pt1_y), (pt2_x, pt2_y), color, border_thickness)\n",
    "    \n",
    "    \n",
    "    # print the label\n",
    "    text = \"{}: {:.4f}\".format(LABELS[classes[box]], scores[box])\n",
    "    (t_w, t_h), _ = cv2.getTextSize(text, font, fontScale=font_scale, thickness=text_thickness)\n",
    "    (text_box_x1, text_box_y1) = (pt1_x, pt1_y - (t_h + text_offset_y))\n",
    "    (test_box_x2, text_box_y2) = ((pt1_x + t_w + text_offset_x), pt1_y)\n",
    "    \n",
    "    cv2.rectangle(image, (text_box_x1, text_box_y1), (test_box_x2, text_box_y2), color, cv2.FILLED)   \n",
    "    cv2.putText(image, text, (pt1_x + text_offset_x,pt1_y - 5), font, font_scale, \n",
    "                                (255, 255, 255), text_thickness)\n",
    "\n",
    "                  \n",
    "plt.figure(figsize=(w*0.05, h*0.05))\n",
    "plt.imshow(image)\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting everything together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#image = imread(\"images/lunch.jpg\")\n",
    "#image = imread(\"images/perth.jpg\")\n",
    "#image = imread(\"images/coffee.jpg\")\n",
    "#image = imread(\"images/wiener_kaffeehaus_2.jpg\")\n",
    "image = imread(\"images/diverse_group_of_women.jpeg\")\n",
    "\n",
    "# determine image size -> will be needed to rescale bounding boxes\n",
    "(h, w) = image.shape[:2]\n",
    "\n",
    "# preprocess image data with rescaling and resizing, \n",
    "blob = cv2.dnn.blobFromImage(image, 1 / 255.0, (416, 416), crop=False)\n",
    "\n",
    "net.setInput(blob)\n",
    "\n",
    "# mesasure the time needed for the object detection \n",
    "start = time.time()\n",
    "layerOutputs = net.forward(ln_out)\n",
    "end = time.time()\n",
    "\n",
    "# Showing spent time for forward pass\n",
    "print('YOLO v3 took {:.4f} seconds'.format(end - start))\n",
    "\n",
    "# Preparing lists for detected bounding boxes, obtained confidences and class's number\n",
    "boxes = []\n",
    "scores = []\n",
    "classes = []\n",
    "\n",
    "# this is our threshold for keeping the bounding box\n",
    "probability_minimum =0.5\n",
    "\n",
    "# iterating through all three outputs\n",
    "for result in layerOutputs:\n",
    "    # Going through all bounding boxes from current output layer\n",
    "    for detection in result:\n",
    "        \n",
    "        # Getting class for current object\n",
    "        scores_current = detection[5:]\n",
    "        class_current = np.argmax(scores_current)\n",
    "\n",
    "        # Getting probability for current object\n",
    "        probability_current = scores_current[class_current]\n",
    "\n",
    "        # Getting object confidence for current object\n",
    "        object_confidence = detection[4]\n",
    "        \n",
    "        # Eliminating weak predictions by minimum probability\n",
    "        if probability_current > probability_minimum:\n",
    "    \n",
    "            # Scaling bounding box coordinates to the initial image size\n",
    "            box_current = np.array(detection[0:4]) * np.array([w, h, w, h])\n",
    "            x_center, y_center, box_width, box_height = box_current.astype('int')\n",
    "            x_min = int(x_center - (box_width / 2))\n",
    "            y_min = int(y_center - (box_height / 2))\n",
    "            x_max = int(x_center + (box_width / 2))\n",
    "            y_max = int(y_center + (box_height / 2))\n",
    "        \n",
    "            # Adding results into prepared lists\n",
    "            boxes.append([x_min, y_min, x_max, y_max])\n",
    "            scores.append(float(probability_current))\n",
    "            classes.append(class_current)\n",
    "            \n",
    "classes=np.array(classes)   \n",
    "scores=np.array(scores)\n",
    "boxes=np.array(boxes)\n",
    "\n",
    "nms_idx = yolo_non_max_supression(boxes, scores, score_threshold=0.5, iou_threshold = 0.5)\n",
    "\n",
    "for box in nms_idx:\n",
    "    # draw the bounding box\n",
    "    color = tuple([int(c) for c in COLORS[classes[box]]])\n",
    "\n",
    "    (pt1_x, pt1_y) = (int(boxes[box, 0]), int(boxes[box, 1]))\n",
    "    (pt2_x, pt2_y) = (int(boxes[box, 2]), int(boxes[box, 3]))\n",
    "    \n",
    "    cv2.rectangle(image, (pt1_x, pt1_y), (pt2_x, pt2_y), color, border_thickness)\n",
    "    \n",
    "    \n",
    "    # print the label\n",
    "    text = \"{}: {:.4f}\".format(LABELS[classes[box]], scores[box])\n",
    "    (t_w, t_h), _ = cv2.getTextSize(text, font, fontScale=font_scale, thickness=text_thickness)\n",
    "    (text_box_x1, text_box_y1) = (pt1_x, pt1_y - (t_h + text_offset_y))\n",
    "    (test_box_x2, text_box_y2) = ((pt1_x + t_w + text_offset_x), pt1_y)\n",
    "    \n",
    "    cv2.rectangle(image, (text_box_x1, text_box_y1), (test_box_x2, text_box_y2), color, cv2.FILLED)   \n",
    "    cv2.putText(image, text, (pt1_x + text_offset_x,pt1_y - 5), font, font_scale, \n",
    "                                (255, 255, 255), text_thickness)\n",
    "\n",
    "                  \n",
    "plt.figure(figsize=(w*0.05, h*0.05))\n",
    "plt.imshow(image)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "for box in nms_idx:\n",
    "    print(LABELS[classes[box]], 'with probability {:.3} at position{}'.format(scores[box],boxes[box,:]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
